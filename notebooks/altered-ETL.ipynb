{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36550324-c873-4175-9d20-f8127d83c173",
   "metadata": {},
   "source": [
    "# 3 – Analysis of the Altered Dataset (`altered.json`)\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Setup and Data Loading](#setup-and-data-loading)\n",
    "3. [3a. Merging Previously Merged Data with Altered Data](#3a-merge-altered)\n",
    "4. [3b. Elevators with More Than 5 Alterations](#3b-more-than-5)\n",
    "5. [3c. Different Combinations of Alteration Type & Status](#3c-alteration-combinations)\n",
    "6. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2e4310-49e8-4917-b779-31303b37418a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<a id=\"introduction\"></a>\n",
    "## 1. Introduction\n",
    "\n",
    "In this third part of our ETL project, we focus on the **Altered** dataset (`altered.json`). We will:\n",
    "\n",
    "- Merge the previously merged License+Installed data with the Altered dataset, keeping all elevators **even if** they have no alterations.\n",
    "- Identify elevators that have **more than 5** alteration records and display them.\n",
    "- Determine different combinations of “Alteration Type” and “Status of Alteration Request” and **count** each combination.\n",
    "\n",
    "This sets the stage for further analysis of how modifications have been requested and handled over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01509080-e96b-4b5c-a3a9-2a6b3047781d",
   "metadata": {},
   "source": [
    "<a id=\"setup-and-data-loading\"></a>\n",
    "## 2. Setup and Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b3c1e6-fb68-4d5f-ae83-0af029d2ad4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/gamikarudev/programming/courses/codeboxx/ai-for-devs/AIC-103_Data_Science_Project/notebooks\n",
      "Files in the current directory: ['.gitkeep', 'licence-ETL.ipynb', 'inspections-ETL.ipynb', '.ipynb_checkpoints', 'installed-ETL.ipynb', 'altered-ETL.ipynb']\n",
      "Error: The file 'merged_installed_data.csv' was not found.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'merged_installed_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: The file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerged_installed_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m was not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Step 4: Load the Altered DataFrame\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Step 3: Load the previously merged data from part 2 \u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# (License + Installed) \u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     merged_installed_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerged_installed_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of merged_installed_df: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmerged_installed_df\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/etl_project/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/etl_project/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/etl_project/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/etl_project/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/etl_project/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'merged_installed_data.csv'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Step 1: Check the current working directory\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "# Step 2: List available files in the directory\n",
    "print(\"Files in the current directory:\", os.listdir())\n",
    "\n",
    "# Step 3: Load the previously merged data from part 2 \n",
    "# (License + Installed) \n",
    "try:\n",
    "    merged_installed_df = pd.read_csv('merged_installed_data.csv')\n",
    "    print(f\"Shape of merged_installed_df: {merged_installed_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: The file 'merged_installed_data.csv' was not found.\")\n",
    "    raise e\n",
    "\n",
    "# Step 4: Load the Altered DataFrame\n",
    "try:\n",
    "    altered_df = pd.read_json('altered.json')\n",
    "    print(f\"Shape of altered_df: {altered_df.shape}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(\"Error: The file 'altered.json' was not found.\")\n",
    "    raise e\n",
    "\n",
    "# Quick check of columns\n",
    "print(\"\\nColumns in merged_installed_df:\", merged_installed_df.columns.tolist())\n",
    "print(\"Columns in altered_df:\", altered_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4138bf0-1f47-4dbc-bab0-1a36f0fbe144",
   "metadata": {},
   "source": [
    "<a id=\"3a-merge-altered\"></a>\n",
    "## 3. 3(a). Merging Previously Merged Data with Altered Data\n",
    "\n",
    "**Requirement**:  \n",
    "“Merge the previously merged dataset with the Altered dataset, **retaining** information even if elevators were not altered.”\n",
    "\n",
    "**Objective**:  \n",
    "- Perform a **left** merge from our installed Data (`merged_installed_df`) onto the `altered_df`. \n",
    "- This ensures we **keep all** rows from the installed dataset even if they do not appear in `altered_df`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350d0c71-a94a-49c9-a3da-1c678c0e795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3(a) STEP 1: Standardize Key Column for the Altered DataFrame ===\n",
    "# The JSON might call it \"Elevating Devices Number\" or \"ElevatingDevicesNumber\" etc.\n",
    "# Let's rename for consistency:\n",
    "altered_df.rename(columns={\n",
    "    'Elevating Devices Number': 'ElevatingDevicesNumber',\n",
    "    'Alteration  Location': 'AlterationLocation'\n",
    "}, inplace=True)\n",
    "\n",
    "# Print columns again to confirm\n",
    "print(\"Altered DF columns after rename:\", altered_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a5bab6-6776-4607-b98a-becfcae1173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3(a) STEP 2: Merge DataFrames ===\n",
    "# We want a left merge on merged_installed_df to keep all those rows,\n",
    "# even if there's no match in altered_df.\n",
    "key_col = 'ElevatingDevicesNumber'\n",
    "\n",
    "merged_altered_df = pd.merge(\n",
    "    merged_installed_df, altered_df,\n",
    "    on=key_col, how='left'\n",
    ")\n",
    "\n",
    "print(\"Number of rows in merged_installed_df:\", len(merged_installed_df))\n",
    "print(\"Number of rows in altered_df:\", len(altered_df))\n",
    "print(\"Number of rows in merged_altered_df (left join):\", len(merged_altered_df))\n",
    "\n",
    "# Optional: how many are left unmatched\n",
    "unmatched_count = merged_altered_df[ 'originating service request number' ].isnull().sum()\n",
    "print(f\"\\nRows with no alteration info: {unmatched_count} (this is expected).\")\n",
    "\n",
    "# Quick peek\n",
    "display(merged_altered_df.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc00b4f-bb84-4fed-bc7a-05793b645594",
   "metadata": {},
   "source": [
    "\n",
    "### Data Quality & Additional Observations\n",
    "\n",
    "- We see **21237** unmatched rows after the left join (where `originating service request number` is `NaN`). That’s expected because not all elevators are altered.  \n",
    "- For those that do have alterations, we see each row references a specific **service request number**, a short **Summary** (like “Minor B Alteration Machine Guarding”), and a **Status**.  \n",
    "- **Location** often includes city, postal code, etc. If we wanted, we could cross‐reference it with the location from the installed dataset to see if any addresses mismatch.  \n",
    "\n",
    "**Potential Next Steps**  \n",
    "1. **Analyze cost or date** of these alterations if cost or date is present or can be derived. Are repeated modifications happening in older buildings, certain city neighborhoods, or with a particular contractor?  \n",
    "2. **Dig into “Rejected”** or “Pending Follow Up” statuses to see if certain building owners are struggling with consistent compliance.  \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5245ee6-782b-4055-8bd7-8c83146ab814",
   "metadata": {},
   "source": [
    "<a id=\"3b-more-than-5\"></a>\n",
    "## 4. 3(b). Elevators with More Than 5 Alterations\n",
    "\n",
    "**Requirement**:  \n",
    "“Identify elevators with **more than 5** alterations and display all rows related to those elevators.”\n",
    "\n",
    "**Approach**:\n",
    "1. Count the number of Alteration records **per elevator** in `merged_altered_df`.\n",
    "2. Filter for those with a count > 5.\n",
    "3. Display all the relevant rows for those elevators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555868f-8016-4e9b-9ae4-9a0fd6c7b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3(b) STEP 1: Group by Elevator & Count Alteration Rows ===\n",
    "# The 'originating service request number' might identify unique alteration rows.\n",
    "# Or we can just count rows.\n",
    "\n",
    "grouped = merged_altered_df.groupby(key_col)['originating service request number'].count()\n",
    "\n",
    "# Elevators with more than 5 alterations:\n",
    "elevators_more_than_5 = grouped[grouped > 5].index.tolist()\n",
    "print(\"Elevators with more than 5 alterations:\", elevators_more_than_5)\n",
    "\n",
    "# === 3(b) STEP 2: Display all rows for these elevators in merged_altered_df ===\n",
    "if len(elevators_more_than_5) > 0:\n",
    "    more_than_5_df = merged_altered_df[merged_altered_df[key_col].isin(elevators_more_than_5)].copy()\n",
    "    print(f\"\\nTotal rows for these {len(elevators_more_than_5)} elevators: {len(more_than_5_df)}\")\n",
    "    display(more_than_5_df.sort_values(by=key_col))\n",
    "else:\n",
    "    print(\"\\nNo elevator has more than 5 alterations.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c72aa65-6286-40a7-afc1-091da1d33cd3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Table of Rows for Elevators With >5 Alterations Interpretation\n",
    "\n",
    "### Meaning & Insights\n",
    "\n",
    "1. **Elevator with Number 14191**  \n",
    "   - Has multiple Minor B alterations. Some are “Closed,” one is “Design Registered,” and one is “Complete.” This suggests repeated smaller‐scope modifications, possibly an ongoing maintenance or modernization cycle.\n",
    "\n",
    "2. **Elevator with Number 62798**  \n",
    "   - Also multiple Minor alterations (some B, some A).  \n",
    "   - Many with status “Passed.” Possibly a building that invests heavily in consistent upgrades.\n",
    "\n",
    "3. **Significance**:  \n",
    "   - We’re seeing that certain buildings or elevator owners handle *frequent* alterations (5+ times). This might correlate with usage, building age, or occupant turnover.  \n",
    "   - Could prompt deeper questions: Are these repeated small changes cost‐effective? Do frequent modifications relate to building occupant demands?\n",
    "\n",
    "By listing all rows for these highly modified elevators, we can investigate patterns in location, owners, or reasons behind repeated changes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82a2a16-9980-4ddd-9bd6-790de527c16f",
   "metadata": {},
   "source": [
    "<a id=\"3c-alteration-combinations\"></a>\n",
    "## 5. 3(c). Different Combinations of “Alteration Type” & “Status of Alteration Request”\n",
    "\n",
    "**Requirement**:  \n",
    "“Determine and count the different combinations of `Alteration Type` and `Status of Alteration Request`.”\n",
    "\n",
    "**Objective**:  \n",
    "- We can do a simple `groupby` or `pd.crosstab` to see how many times each `(Alteration Type, Status)` pair occurs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac644c4-dbaa-4ce6-bdc0-c5ec712fda3f",
   "metadata": {},
   "source": [
    "**Optional**: We could do a pivot or crosstab for a more matrix‐style view:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fcc45-2219-4cc2-bf92-456b5c1b7974",
   "metadata": {},
   "outputs": [],
   "source": [
    "combination_crosstab = pd.crosstab(merged_altered_df['Alteration Type'], merged_altered_df['Status of Alteration Request'])\n",
    "print(\"\\nCrosstab of Alteration Type vs Status:\")\n",
    "display(combination_crosstab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb318f2-a972-4733-83d9-5242f542aa3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Below is a short **interpretation** and **discussion** of the **crosstab** and **sample rows**, explaining what these results might mean and highlighting potential insights. It should help any non‐technical stakeholders make sense of the data and see where further exploration might be useful.\n",
    "\n",
    "---\n",
    "\n",
    "### Crosstab Interpretation\n",
    "\n",
    "#### What Does Each Column Mean?\n",
    "\n",
    "- **Alteration Type**:  \n",
    "  - **ED-Major Alteration** typically indicates a significant upgrade or modernization.  \n",
    "  - **ED-Minor A Alteration** and **ED-Minor B Alteration** are smaller‐scope modifications. (We might infer “Minor A” vs. “Minor B” has different code designations, possibly meaning different extents or safety impacts.)\n",
    "\n",
    "- **Status of Alteration Request** (each column):\n",
    "  - **Passed** generally means the alteration request was completed and passed inspection or final sign‐off.\n",
    "  - **Closed** could mean the record has been closed out, though not always “passed” (perhaps the project ended differently).\n",
    "  - **Complete** might represent partial or full completion. \n",
    "  - **Design Registered**, **Conditionally Registered**, or **On Hold** are likely statuses within elevator production and alteration  workflow. \n",
    "  - **Pending Follow Up** or **Rejected** means the process wasn’t fully accepted.\n",
    "\n",
    "#### Observing Patterns\n",
    "\n",
    "- **ED-Minor A Alteration** has **13,080** “Passed” records, which is by far the largest single combination. This indicates that the **most common** scenario in the dataset is a Minor A alteration that successfully concluded (passed).\n",
    "- **ED-Major Alteration** has **6,370** “Passed” records, also significant but about half as many as Minor A. We also see 392 are “Pending Follow Up,” meaning there’s still some action required as of the data captured in the data sets. \n",
    "- **ED-Minor B Alteration** has **7,086** “Passed” records. Interestingly, it also has **454** “Design Registered”—which means these Minor B requests are still in some form of design or registration stage more often than for Minor A.\n",
    "\n",
    "##### Key Takeaways\n",
    "1. **Most Common Status**: “Passed” across all three alteration types, making up the bulk of concluded alterations.\n",
    "2. **Design Registrations** Appear More Common in Minor B Alterations than A or Major (454 vs. 63 or 79). Possibly Minor B tasks often require design registration steps.\n",
    "3. **Possible High Pending Follow‐Ups**: Notably, Minor A has **1,058** “Pending Follow Up,” which might indicate a backlog or slower finalization process, since it's more likely that most elevators will have minor alterations required more often than severe or major alterations. \n",
    "\n",
    "These patterns can help us prioritize resources or investigate further why Minor A has so many follow‐ups, or Minor B has a large number of design registrations.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde731ab-7116-4feb-974b-0af98dcfa5bd",
   "metadata": {},
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusion\n",
    "\n",
    "In **Part 3** of our ETL project, we merged the combined (License + Installed) dataset with the Altered dataset, ensuring we retained every elevator—even those without any alterations. Using these unified records, we identified and displayed elevators having more than five alterations, providing a clear view of assets that undergo unusually frequent modifications. We also compiled a summary of “Alteration Type” paired with “Status of Alteration Request,” revealing that:\n",
    "\n",
    "- **Minor A Alterations** dominate the dataset, most commonly concluding with a “Passed” status, yet also showing a high number of “Pending Follow Up” records.  \n",
    "- **Major** and **Minor B Alterations** are less frequent but still exhibit a significant portion marked as “Passed,” reflecting successfully completed modifications.  \n",
    "- A small subset of elevators have a disproportionately high count of alterations (5+), indicating these assets undergo repeated or complex modification cycles.\n",
    "\n",
    "This analysis provides a **springboard** for deeper questions:\n",
    "- What drives multiple smaller alterations versus fewer major overhauls?\n",
    "- Are repeated alterations correlated with older infrastructure, specific locations, or particular building owners?\n",
    "- How do different alteration statuses track over time, and what cost or compliance implications arise from “Pending Follow Up” or “Rejected” statuses?\n",
    "\n",
    "By unifying and exploring the Altered dataset in tandem with License and Installed data, we’ve laid the groundwork for further insights into how elevator modifications impact operational reliability and cost. **Future steps** may include integrating Inspection data for an end‐to‐end picture of each elevator’s lifecycle, investigating cost patterns, and establishing predictive models to optimize maintenance strategies and safety outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fcb205-835f-497c-9967-a43b5085e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_altered_df.to_csv('merged_altered_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71220e9c-8010-4a30-90da-56ec6291b0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af4f2de-858f-4c8a-86c8-2b67ec678801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4412e-5b94-4fea-8ef0-05ac4662acde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf99d0-defe-4bb2-97e0-90a017131cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc92637-35b6-4049-ba81-e009df9589df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655216a1-730a-4c14-9d0a-e59d46f67f61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b93d0-1835-4abe-aad3-67dd25979ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
